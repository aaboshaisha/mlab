{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9093c6f-3915-4059-bab6-194a0165f652",
   "metadata": {},
   "source": [
    "### From counting to embeddings:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e344ff30-ee01-4d19-8a89-3f1d18d01462",
   "metadata": {},
   "source": [
    "Previously our solution to the problem of predicting the next token / character was to initially build a probability distribution over the next token `P(ch2|ch1)` by counting the frequencies of occurence from the data. We built a 27 x 27 table where each cell represented `P(ch2|ch1)` for all possible character pairs. We then could sample from this model to generate new names. \n",
    "\n",
    "We then tried to use a simple one layer NN to learn these probabilities instead of explcitly counting them from the data. We extracted input and output dataset from our data and used gradient descent to optimize the weights of the model. The weights would then be transformed by some mathematical operations to represent probabilties we could compute loss for and also sample from after we train the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c08e11a-7836-4249-9eca-9b47678b68e2",
   "metadata": {},
   "source": [
    "The problem with the frequency table approach is that it can't scale. If we try to predict the next character given 1 previous character (called context of 1), we want a 27 x 27 table. Suppose rows represent the previous character, think what the size of the row needs to be if we want to take 2 characters / tokens as context, or 3 or more ..:\n",
    "- context of 1: 27 rows\n",
    "- context of 2: 27 x 27 rows (possible combinations of 2 tokens)\n",
    "- context of 3: 27 x 27 x 27\n",
    "- and so on\n",
    "\n",
    "We'll find the size of the table grows \"exponentially\" with the size of the context. \n",
    "\n",
    "This won't work very well. This is why we needed the neural network approach. It's more flexible and scales better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be38e771-ca5e-43c8-99b9-c45debc67675",
   "metadata": {},
   "source": [
    "More context, joint probability and dimensionality;\n",
    "\n",
    "When taking 1 token as context, we're trying to learn `P(ch2 | ch1)`. We did it via counting: \n",
    "\n",
    "$$P(\\text{{ch2}}|\\text{{ch1}}) = \\frac{{\\text{{Count}}(\\text{{ch2, ch1}})}}{{\\text{{Count}}(\\text{{ch1, ch1}}) + \\text{{Count}}(\\text{{ch2, ch1}}) + \\ldots + \\text{{Count}}(\\text{{ch26, ch1}})}}$$\n",
    "\n",
    "ie:\n",
    "\n",
    "$$P(\\text{ch2}|\\text{ch1}) = \\frac{\\text{Count}(\\text{ch2, ch1})}{\\sum_{i=1}^{26} \\text{Count}(\\text{chi, ch1})}$$\n",
    "\n",
    "\n",
    "If we take 2 as context, we'll be learning `(P ch3 | ch1, ch2)`\n",
    "\n",
    "\n",
    "$$P(\\text{ch3} | \\text{ch1}, \\text{ch2}) = \\frac{\\text{Count}(\\text{ch1, ch2, ch3})}{\\text{Count}(\\text{ch1, ch2, a}) + \\text{Count}(\\text{ch1, ch2, b}) + \\ldots + \\text{Count}(\\text{ch1, ch2, z})}$$\n",
    "\n",
    "In this expanded version:\n",
    "\n",
    "- $\\text{Count}(\\text{ch1, ch2, ch3})$ represents the frequency of the sequence $\\text{ch1, ch2}$ immediately followed by $\\text{ch3}$.\n",
    "\n",
    "- The denominator is the sum of counts for the sequence $\\text{ch1, ch2}$ followed by each possible character in the English alphabet (from 'a' to 'z'). This sum gives the total number of times the sequence $\\text{ch1, ch2}$ is followed by any character, serving as the normalization factor to convert raw counts into a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3c6695-1c76-41cb-a90a-63fe4944a87e",
   "metadata": {},
   "source": [
    "Using the neural network, we try to learn probability model. The core idea is that the likelihood of any given token sequence in a language can be broken down into the product of conditional probabilities. Each token's probability depends on the sequence of tokens that precede it.\n",
    "\n",
    "Consider a sequence of tokens/characters from 1 to $T$. The probability of this entire sequence is the product of the conditional probabilities of each token/character given all the previous tokens/characters. \n",
    "\n",
    "$$\\hat{P}(t_{1}^{T}) = \\hat{P}(t_1) \\times \\hat{P}(t_2 | t_1) \\times \\hat{P}(t_3 | t_1, t_2) \\times \\ldots \\times \\hat{P}(t_T | t_{1}^{T-1})$$\n",
    "\n",
    "=\n",
    "\n",
    "$$\\hat{P}(t_{1}^{T}) = \\prod_{t=1}^{T} \\hat{P}(t_t | t_{1}^{t-1})$$\n",
    "\n",
    "\n",
    "**In a nutshell, the n-gram models (bigram, trigram, etc) construct tables of conditional probabilities for the next character.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee0984-a125-410e-876a-540168b92fbd",
   "metadata": {},
   "source": [
    "The question now is, how do we provide more context to the NN. We also want to make the network itself bigger (more layers).\n",
    "\n",
    "In building our 1 layer NN, we stumbled upon the idea of the embedding being equivalent to lookup table. We first turned tokens to integers. We then did one-not-encoding of integers in order to be able to provide them as input to the NN. The NN was one layer of neurons that do dot product of their inputs with synpases / weights. We saw how doing matrix multiplication of one-hot-encoded vector with a matrix of weights is equivalent to pulling out / indexing into the matrix to pluck out the row vector of weights that represented the probability distribution for any character X over its next possible 27 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f6ed2-e257-4f00-897e-c87b1f913d75",
   "metadata": {},
   "source": [
    "Now, we'll think of embedding in a different sense as a different way of encoding inputs (characters / tokens) provided to the neural network.\n",
    "\n",
    "In the 1-layer approach, we used one-hot encoding (where each token is represented by a vector of the size of the vocabulary with all zeros except for a single one at the index representing the token). This is a sparse representation and could be very high dimensional (think of not a character-level language model of 26 characters but a text vocabulary of size 100,000 that could generate 10,000 tokens - this is a 10,000 vector input to your network).\n",
    "\n",
    "Instead, we'll use token embeddings. The idea is to represent each token not as 1 in a one-hot-encoded vector space of vocabulary but we'll think of each token / word as having some hidden characteristics / features (if we're thinking of objects in the real world, this is the difference between representing each object as 1 in a one-hot-encoded table of ALL objects inte world but instead thinking of its characteristics such as size, shape, color, etc and representing each object as a vector of initially random numbers $[0.3, 0.5, .. ]$ that represent measurements over these characteristics / features). Embeddings as such compactly encode tokens in a much smaller dimensional space. \n",
    "\n",
    "The innovation here becomes that we allow the neural network not only to learn the sequence of tokens, but also learn the embeddings themselves. The distributional hypothesis (the foundational idea behind word embeddings), posits that words that appear in similar contexts tend to have similar meanings. By training models on large corpora of text, embeddings inherently learn these patterns, as the model's performance improves when similar words have similar embeddings.\n",
    "\n",
    "Another useful gain is the process of learning embeddings effectively acts as a form of dimensionality reduction, where the high-dimensional space of the vocabulary is compressed into a lower-dimensional, dense vector space. This compression forces the model to encode as much information as possible about each word into a limited number of dimensions, leading to the emergence of semantically and syntactically meaningful patterns.\n",
    "\n",
    "The goal is then to simultaneously learn the word feature vectors and the parameters of the joint probability function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9aa9c694-3d9b-423d-89bc-960116e190fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1588e323-fa36-4dd9-a2f8-ce73ee51e8f0",
   "metadata": {},
   "source": [
    "### Embeddings:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c41f39d-0ef6-46df-b813-9367cebfd232",
   "metadata": {},
   "source": [
    "We'll build our model following the [Bengio et al](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf) paper. We'll build it for our character level language model. We'll take 3 characters as input. We'll embed these in an intially 2D embedding matrix. We'll have 1 hidden layer and final output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea41cf45-daaf-4312-9426-a946732c3f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt').read().splitlines()\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fe0ad19-1113-4db2-8e70-e65672103978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(list(set(''.join(words))))\n",
    "vocab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2988ced5-8196-49c3-8a2b-aa1cc5d40947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding and decoding\n",
    "stoi = {s:i+1 for i,s in enumerate(vocab)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f385d01-f778-48b4-a65e-bfeabe0b130c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', '.', '.'] .\n",
      "['.', '.', '.'] e\n",
      "['.', '.', 'e'] m\n",
      "['.', 'e', 'm'] m\n",
      "['e', 'm', 'm'] a\n",
      "['m', 'm', 'a'] .\n"
     ]
    }
   ],
   "source": [
    "sz = 3\n",
    "context = sz * ['.']\n",
    "for w in words[:1]:\n",
    "    w = '.' + w + '.'\n",
    "    for ch in w:\n",
    "        print(context, ch)\n",
    "        context = context[1:] + [ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3f6eefe-9818-4dbe-b8c8-67e431e41663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, ys = [], []\n",
    "context_size = 3\n",
    "n = 5 #number of words to consider in dataset \n",
    "\n",
    "context = context_size * [0]\n",
    "for w in words[:n]:\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        context = context[1:] + [ix]\n",
    "        xs.append(context)\n",
    "        ys.append(ix)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "xs.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24d22a08-9fce-4c21-b723-4f527fb4685d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 2])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embedding matrix\n",
    "emb_size = 2\n",
    "C = torch.randn(27, emb_size)\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f370fc0-e39e-4b6e-81a9-9d6c3025e864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embed the dataset - extract embeddings for input indices\n",
    "emb = C[xs] # how to simultaneously embed multiple inputs\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b0e929b5-c72c-4b78-bb57-b405cc661a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjust dimensions to make it a 2D matrix\n",
    "emb.view(-1, context_size * emb_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e2590b97-869d-4cf4-a4ab-2bc6de2e65f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 100]), torch.Size([100, 27]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "W1 = torch.randn(context_size * emb_size, hidden_size)\n",
    "b1 = torch.randn(hidden_size)\n",
    "W2 = torch.randn(hidden_size, 27)\n",
    "b2 = torch.randn(27)\n",
    "W1.shape, W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "634703ff-be3a-45a5-a4f3-a39abf393961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass\n",
    "h = torch.tanh(emb.view(-1, context_size * emb_size) @ W1 + b1)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "39aa8ac3-e549-4a01-bd04-15ddcf5315e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = h @ out + b2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8f34faf9-31fa-419a-8db2-d03563d1c350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate loss as before with 1 layer model\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f6be28fc-6087-4cba-b0aa-af14742cf1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1881e-02, 6.0892e-04, 1.5999e-04, 8.8785e-05, 1.2108e-07, 3.4456e-11,\n",
       "        2.8165e-03, 9.2810e-07, 9.0839e-01, 1.0322e-07, 2.1488e-05, 1.1048e-04,\n",
       "        2.7073e-02, 2.6118e-06, 4.1120e-09, 4.7512e-08, 2.1020e-09, 5.2692e-06,\n",
       "        1.0211e-05, 4.3473e-02, 2.5301e-06, 1.1633e-07, 9.5978e-08, 1.0293e-04,\n",
       "        1.0196e-07, 5.1491e-03, 9.7325e-05])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5a43bc26-f612-4d6b-87d1-153a96299413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "82f4efda-1b51-46fc-8b8d-a642a1378c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pluck out the probabilities for correct labels to compute loss on them\n",
    "probs[torch.arange(32), ys].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "876cce8f-3b90-486d-bdbc-55e54b4efe21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.0360)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute average negative log likelihood \n",
    "loss = -probs[torch.arange(32), ys].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0356ac8-1209-41b4-9d79-5fdc07ee181a",
   "metadata": {},
   "source": [
    "### Splitting to train / val / test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ce5e7093-7cb5-4349-8ab5-34913fc1bd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 3\n",
    "\n",
    "def build_dataset(words):\n",
    "    xs, ys = [], []\n",
    "    for w in words:\n",
    "        context = context_size * [0]\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            xs.append(context)\n",
    "            ys.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "\n",
    "    xs = torch.tensor(xs)\n",
    "    ys = torch.tensor(ys)\n",
    "    print(xs.shape, ys.shape)\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9843315e-66c3-4458-9a20-7a3a08ce8530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "xs, ys = build_dataset(words[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "433aba42-7a4b-456d-95ae-5f661a108154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182421, 3]) torch.Size([182421])\n",
      "torch.Size([22832, 3]) torch.Size([22832])\n",
      "torch.Size([22893, 3]) torch.Size([22893])\n"
     ]
    }
   ],
   "source": [
    "# How we'll split into train / dev / test sets: \n",
    "# -> random shuffle words then slice\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "xtrn, ytrn = build_dataset(words[ :n1])\n",
    "xdev, ydev = build_dataset(words[n1:n2])\n",
    "xte, yte = build_dataset(words[n2: ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6b82a637-747e-4703-afc0-d55b0a055ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 100]), torch.Size([100, 27]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape, W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ee5f1067-a35e-4486-8ca9-16bfa2609b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 100]), torch.Size([100, 27]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params and hyperparams\n",
    "lr = 0.01\n",
    "emb_size = 2\n",
    "hidden_size = 100\n",
    "\n",
    "C = torch.randn(27, emb_size)\n",
    "W1 = torch.randn(context_size * emb_size, hidden_size)\n",
    "b1 = torch.randn(hidden_size)\n",
    "W2 = torch.randn(hidden_size, 27)\n",
    "b2 = torch.randn(27)\n",
    "W1.shape, W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "65d27ed4-217d-443a-8d8e-d8310689f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [C, W1, W2, b1, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "300bbcd0-5e04-4590-b849-a1d8c6c3d15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6d436a8a-b288-40f6-bc37-cb292bd48220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.976476669311523\n"
     ]
    }
   ],
   "source": [
    "# the training loop\n",
    "lossi = []\n",
    "stepi = []\n",
    "\n",
    "for i in range(100):\n",
    "    #forward pass\n",
    "    xenc = C[xtrn]\n",
    "    h = torch.tanh(xenc.view(-1, context_size * emb_size) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    # compute loss\n",
    "    loss = F.cross_entropy(logits, ytrn)\n",
    "    # zero grad\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    # backprop\n",
    "    loss.backward()\n",
    "    # update weights\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(loss.item())\n",
    "\n",
    "    # track statistics\n",
    "    lossi.append(loss.item())\n",
    "    stepi.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8b916214-c12f-4740-9c46-b8f8c9f5ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(stepi, lossi);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "83143c69-3c27-4416-bb71-f7dde989df6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 100]) torch.Size([100, 27])\n"
     ]
    }
   ],
   "source": [
    "# params and hyperparams\n",
    "lr = 0.01\n",
    "emb_size = 2\n",
    "hidden_size = 100\n",
    "batch_size = 32\n",
    "\n",
    "C = torch.randn(27, emb_size)\n",
    "W1 = torch.randn(context_size * emb_size, hidden_size)\n",
    "b1 = torch.randn(hidden_size)\n",
    "W2 = torch.randn(hidden_size, 27)\n",
    "b2 = torch.randn(27)\n",
    "print(W1.shape, W2.shape)\n",
    "\n",
    "parameters = [C, W1, W2, b1, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "sum(p.nelement() for p in parameters) # number of parameters in total\n",
    "\n",
    "# keep stats here to avoid re-initializing every time we loop\n",
    "lossi = []\n",
    "stepi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a4891681-8028-403b-ad4e-19e53d04884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make it faster by training on minibatches\n",
    "for i in range(50000):\n",
    "    # create mini-batches\n",
    "    ixs = torch.randint(0, xtrn.size(0), (batch_size, )) # random indices / samples from training set\n",
    "    xs = xtrn[ixs]\n",
    "    ys = ytrn[ixs]\n",
    "    \n",
    "    xenc = C[xs]\n",
    "    h = torch.tanh(xenc.view(-1, context_size * emb_size) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "\n",
    "    # loss\n",
    "    loss = F.cross_entropy(logits, ys)\n",
    "    # zero grad\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    #backprop\n",
    "    loss.backward()\n",
    "\n",
    "    lr = 0.1 if i < 10000 else 0.01\n",
    "    # weight update\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    lossi.append(loss.item())\n",
    "    stepi.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "41c1e90b-6b18-460c-90d5-1f8d4e09ae4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stepi, lossi);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "805f0060-2ad7-432e-bc54-867ccd87a120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1321563720703125"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3b539cf5-6298-4ef9-b62a-0659ab8a7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on dev set\n",
    "# to eval-> full pass through network and compute final loss\n",
    "def eval_loss(x,y):\n",
    "    with torch.no_grad():         \n",
    "        xenc = C[x]\n",
    "        h = torch.tanh(xenc.view(-1, context_size * emb_size) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "058ca998-6656-41c8-a54d-5d1d1b8dfd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.318882942199707\n"
     ]
    }
   ],
   "source": [
    "eval_loss(xdev, ydev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4b831410-f837-4343-a19f-2bc20cdbdf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mria.\n",
      "kayan.\n",
      "seel.\n",
      "ndynyal.\n",
      "rethastendrlee.\n",
      "aderedielin.\n",
      "shi.\n",
      "jen.\n",
      "edellestanar.\n",
      "kayzioh.\n"
     ]
    }
   ],
   "source": [
    "# sampling from this distribution: we want to get probabilities to sampe from.\n",
    "# these will be derived from the logits in the final layer\n",
    "# as before, we sample letter after another\n",
    "# we start at . . .\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(10):\n",
    "    out = []\n",
    "    context = [0] * context_size\n",
    "    while True:\n",
    "        xenc = C[context]\n",
    "        h = torch.tanh(xenc.view(-1, context_size * emb_size) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69e9f93-5007-418a-877a-3315c6eb099c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
